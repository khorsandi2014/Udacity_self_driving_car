{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "In this part, there are 20 chessboard images and camera calibration is done on these images to obtain nessecary parameters for the next steps. Three of the images are not shown since the whole chessboard is not in the image and some of corners are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images for calibration:  20\n"
     ]
    }
   ],
   "source": [
    "# Camera Calibration\n",
    "\n",
    "import glob\n",
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "def cameraCalibration():\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "    directory = './output_images'\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "    print(\"number of images for calibration: \" , len(images))\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            #print(fname)\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            #corner_img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            #cv2.imwrite(directory + '/display_corners_'+ fname[13:] ,corner_img)\n",
    "            #cv2.waitKey(500)\n",
    "            #axs[count].axis('off')\n",
    "            #axs[count].imshow(corner_img)\n",
    "    return objpoints, imgpoints\n",
    "    #cv2.destroyAllWindows()\n",
    "objpoints, imgpoints = cameraCalibration()\n",
    "fname = './test_images/' + 'test6.jpg'\n",
    "img = mpimg.imread(fname)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, \n",
    "                                                   img.shape[:2], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions\n",
    "Here, we define several functions for undistortion, thresholding, warped and selecting regin of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function that takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def undistort_img(img,mtx,dist):\n",
    "    #print(ret, mtx, dist)\n",
    "    undistorted_image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undistorted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_thresholds(img):\n",
    "    \n",
    "    # convert to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    h,w = gray.shape\n",
    "    \n",
    "    # apply x gradient threshold and dir graadient threshold\n",
    "    sx_binary = abs_sobel_thresh(gray, 'x', 10, 200)\n",
    "    dir_binary = dir_threshold(gray, thresh=(np.pi/6, np.pi/2))\n",
    "    \n",
    "    # combine the gradient and direction thresholds.\n",
    "    gradients_combined = ((sx_binary == 1) & (dir_binary == 1))\n",
    "    \n",
    "    # R & G thresholds so that yellow lanes are detected well.\n",
    "    color_threshold = 150\n",
    "    R = img[:,:,0]\n",
    "    G = img[:,:,1]\n",
    "    color_combined = np.zeros_like(R)\n",
    "    rg_combined = (R > color_threshold) & (G > color_threshold)\n",
    "    \n",
    "    \n",
    "    # color channel thresholds\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    l = hls[:,:,1]\n",
    "    \n",
    "    # S channel performs well for detecting bright yellow and white lanes\n",
    "    s_thresh = (100, 255)\n",
    "    s_condition = (s > s_thresh[0]) & (s <= s_thresh[1])\n",
    "\n",
    "    l_thresh = (120, 255)\n",
    "    l_condition = (l > l_thresh[0]) & (l <= l_thresh[1])\n",
    "\n",
    "    # combine all the thresholds\n",
    "    color_combined[(rg_combined & l_condition) & \n",
    "                   (s_condition | gradients_combined)] = 1\n",
    "    \n",
    "    # apply the region of interest mask\n",
    "    mask = np.zeros_like(color_combined)\n",
    "    region_of_interest_vertices = np.array([[0,h-1], [w/2, int(0.5*h)],\n",
    "                                            [w-1, h-1]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [region_of_interest_vertices], 1)\n",
    "    thresholded = cv2.bitwise_and(color_combined, mask)\n",
    "    \n",
    "    return thresholded\n",
    "    \n",
    "    \n",
    "    \n",
    "def abs_sobel_thresh(gray, orient='x', thresh_min=0, thresh_max=255):\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1)\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    max_value = np.max(abs_sobel)\n",
    "    binary_output = np.uint8(255*abs_sobel/max_value)\n",
    "    threshold_mask = np.zeros_like(binary_output)\n",
    "    threshold_mask[(binary_output >= thresh_min) & (binary_output <= thresh_max)] = 1\n",
    "    return threshold_mask\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    direction = np.arctan2(abs_sobel_y,abs_sobel_x)\n",
    "    direction = np.absolute(direction)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    mask = np.zeros_like(direction)\n",
    "    mask[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def warped(gray,src_points,dst_points):\n",
    "    M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "    Minv = cv2.getPerspectiveTransform(dst_points,src_points)\n",
    "    warped = cv2.warpPerspective(gray, M, (gray.shape[1],gray.shape[0]), \n",
    "                                 flags=cv2.INTER_LINEAR)        \n",
    "    return warped, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Image\n",
    "We show results for one test image. The captions below each image is about the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "import collections\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = collections.deque(12*[0.0, 0.0, 0.0], 12)\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Lanes\n",
    "Here, we perform finding_lanes function to find left and right lanes. the results are visualized for windows search and lane detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement Sliding Windows and Fit a Polynomial\n",
    "def finding_lanes(binary_warped):\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 60\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    if (left_line_obj.detected == False) or (right_line_obj.detected == False):\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "           # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on \n",
    "            #their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        left_line_obj.detected = True\n",
    "        right_line_obj.detected = True\n",
    "\n",
    "    else:\n",
    "        # Assume you now have a new warped binary image \n",
    "        # from the next frame of video (also called \"binary_warped\")\n",
    "        # It's now much easier to find line pixels!\n",
    "        left_lane_inds = ((nonzerox > (left_line_obj.current_fit[0]*(nonzeroy**2) + \n",
    "                                       left_line_obj.current_fit[1]*nonzeroy + \n",
    "                                       left_line_obj.current_fit[2] - margin)) & \n",
    "                          (nonzerox < (left_line_obj.current_fit[0]*(nonzeroy**2) + \n",
    "                                       left_line_obj.current_fit[1]*nonzeroy + \n",
    "                                       left_line_obj.current_fit[2] + margin))) \n",
    "\n",
    "        right_lane_inds = ((nonzerox > (right_line_obj.current_fit[0]*(nonzeroy**2) + \n",
    "                                        right_line_obj.current_fit[1]*nonzeroy + \n",
    "                                        right_line_obj.current_fit[2] - margin)) & \n",
    "                           (nonzerox < (right_line_obj.current_fit[0]*(nonzeroy**2) + \n",
    "                                        right_line_obj.current_fit[1]*nonzeroy + \n",
    "                                        right_line_obj.current_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    if (len(leftx) < 1600):\n",
    "        leftx = left_line_obj.allx\n",
    "        lefty = left_line_obj.ally\n",
    "        left_line_obj.detected = False\n",
    "    else:\n",
    "        left_line_obj.allx = leftx\n",
    "        left_line_obj.ally = lefty\n",
    "    if (len(rightx) < 1600):\n",
    "        rightx = right_line_obj.allx\n",
    "        righty = right_line_obj.ally\n",
    "        right_line_obj.detected = False\n",
    "    else:\n",
    "        right_line_obj.allx = rightx\n",
    "        right_line_obj.ally = righty\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    #check distanse and cu\n",
    "    if (left_line_obj.current_fit[0] == False):\n",
    "        left_line_obj.current_fit = left_fit\n",
    "        right_line_obj.current_fit = right_fit\n",
    "        \n",
    "    if (abs(left_line_obj.current_fit[1] - left_fit[1]) > 0.2):\n",
    "        left_line_obj.current_fit = left_line_obj.best_fit\n",
    "        left_line_obj.detected = False\n",
    "    else:\n",
    "        left_line_obj.current_fit = left_fit\n",
    "        left_line_obj.recent_xfitted.pop()\n",
    "        left_line_obj.recent_xfitted.appendleft(left_line_obj.current_fit)\n",
    "        avg = np.array([0,0,0], dtype='float')\n",
    "        for element in left_line_obj.recent_xfitted:\n",
    "            avg = avg + element\n",
    "        left_line_obj.best_fit = avg / (len(left_line_obj.recent_xfitted))\n",
    "        \n",
    "    if (abs(right_line_obj.current_fit[1] - right_fit[1]) > 0.2):\n",
    "        right_line_obj.current_fit = right_line_obj.best_fit\n",
    "        right_line_obj.detected = False\n",
    "    else:\n",
    "        right_line_obj.current_fit = right_fit\n",
    "        right_line_obj.recent_xfitted.pop()\n",
    "        right_line_obj.recent_xfitted.appendleft(right_line_obj.current_fit)\n",
    "        avg = np.array([0,0,0], dtype='float')\n",
    "        for element in right_line_obj.recent_xfitted:\n",
    "            avg = avg + element\n",
    "        right_line_obj.best_fit = avg / (len(right_line_obj.recent_xfitted))\n",
    "        \n",
    "    if (abs(right_line_obj.current_fit[1] - right_fit[1]) > 0.4 and\n",
    "        abs(left_line_obj.current_fit[1] - left_fit[1]) < 0.1):\n",
    "        right_line_obj.current_fit[0] = left_line_obj.current_fit[0]\n",
    "        right_line_obj.current_fit[1] = left_line_obj.current_fit[1]\n",
    "        right_line_obj.current_fit[2] = left_line_obj.current_fit[2] + 600\n",
    "        right_line_obj.recent_xfitted.pop()\n",
    "        right_line_obj.recent_xfitted.appendleft(right_line_obj.current_fit)\n",
    "        avg = np.array([0,0,0], dtype='float')\n",
    "        for element in right_line_obj.recent_xfitted:\n",
    "            avg = avg + element\n",
    "        right_line_obj.best_fit = avg / (len(right_line_obj.recent_xfitted))\n",
    "        \n",
    "    if (abs(left_line_obj.current_fit[1] - left_fit[1]) > 0.4 and\n",
    "        abs(right_line_obj.current_fit[1] - right_fit[1]) < 0.1):\n",
    "        left_line_obj.current_fit = left_fit\n",
    "        left_line_obj.recent_xfitted.pop()\n",
    "        left_line_obj.recent_xfitted.appendleft(left_line_obj.current_fit)\n",
    "        avg = np.array([0,0,0], dtype='float')\n",
    "        for element in left_line_obj.recent_xfitted:\n",
    "            avg = avg + element\n",
    "        left_line_obj.best_fit = avg / (len(left_line_obj.recent_xfitted))\n",
    "\n",
    "    return left_fit, right_fit,out_img, leftx, lefty, rightx, righty\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def curveture_offset(binary_warped, left_fit, right_fit, leftx, lefty, rightx, righty):\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    #ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + \n",
    "                           left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + \n",
    "                            right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, right_curverad)\n",
    "    # Example values: 1926.74 1908.48\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    if len(leftx) != 0 and len(rightx) != 0:\n",
    "        #print('here', len(leftx), len(lefty))\n",
    "        left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        # Calculate the new radii of curvature\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + \n",
    "                               left_fit_cr[1])**2)**1.5) / \\\n",
    "        np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + \n",
    "                                right_fit_cr[1])**2)**1.5) / \\\n",
    "        np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    curverad = np.mean([left_curverad, right_curverad])\n",
    "    \n",
    "    image_centre = 1280/2 * xm_per_pix\n",
    "    \n",
    "    offset = 0\n",
    "    if left_fit is not None and right_fit is not None:\n",
    "        left_lane_bottom = (left_fit_cr[0] * (y_eval * ym_per_pix) ** 2 + \n",
    "                            left_fit_cr[1] * (y_eval * ym_per_pix) + left_fit_cr[2])\n",
    "\n",
    "        right_lane_bottom = (right_fit_cr[0] * (y_eval * ym_per_pix) ** 2 + \n",
    "                             right_fit_cr[1] * (y_eval * ym_per_pix) + right_fit_cr[2])\n",
    "\n",
    "        centre = float(right_lane_bottom + left_lane_bottom) / 2\n",
    "        offset = (image_centre - centre)\n",
    "        \n",
    "    #print('Offset from Center: ', offset, ' m')\n",
    "    return curverad, offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "def draw_lines_offset(warped_binary,left_fit, right_fit,Minv,undist,curverad, offset,\n",
    "                      plot_flag='True'):\n",
    "    \n",
    "    ploty = np.linspace(0, warped_binary.shape[0]-1, warped_binary.shape[0] )\n",
    "    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    warp_zero = np.zeros_like(warped_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective \n",
    "    # matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, \n",
    "                                  (color_warp.shape[1], color_warp.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    cv2.putText(result, 'Curvature Rad: {} m'.format(int(curverad)), (120,140),\n",
    "             fontFace = 16, fontScale = 1.5, color=(0,0,255), thickness = 6)\n",
    "    cv2.putText(result, \"Offset: {:.2f} m\".format(float(offset)), (120,240),\n",
    "             fontFace = 16, fontScale = 1.5, color=(0,0,255), thickness = 6)\n",
    "    \n",
    "    if plot_flag == 'True':\n",
    "        plt.imshow(result)\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the pipleline for detecting lane on road images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def advance_line_detection_pipeline(image,plot_flag = 'False'):\n",
    "    \n",
    "    undistorted_img = undistort_img(image,mtx,dist)\n",
    "    gradient_thresh_binary = combine_thresholds(undistorted_img)\n",
    "    src_points = np.float32([[180, image.shape[0]], [575, 460], \n",
    "                  [705, 460], [1150, image.shape[0]]])\n",
    "    # Define 4 destination points\n",
    "    dst_points = np.float32([[320, image.shape[0]], [320, 0], \n",
    "                  [960, 0], [960, image.shape[0]]])\n",
    "    warped_binary,Minv = warped(gradient_thresh_binary,src_points,dst_points)\n",
    "    left_fit, right_fit, out_img,leftx, lefty, rightx, \\\n",
    "    righty = finding_lanes(warped_binary)\n",
    "    curverad, offset = curveture_offset(warped_binary, left_fit, right_fit,\\\n",
    "                                        leftx, lefty, rightx, righty)\n",
    "    output = draw_lines_offset(warped_binary,left_fit, right_fit,Minv,\n",
    "                               undistorted_img,curverad,offset,plot_flag)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on Video\n",
    "\n",
    "In this last part, we test the pipeline on one video and represent the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 947/1261 [02:38<00:52,  5.99it/s]"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "left_line_obj = Line()\n",
    "right_line_obj = Line()\n",
    "white_output = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter \n",
    "#subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and \n",
    "#end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")#.subclip(30,45)\n",
    "white_clip = clip1.fl_image(advance_line_detection_pipeline) \n",
    "#NOTE: this function  expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
